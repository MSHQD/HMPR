{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSHQD/HWR/blob/main/Language_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u93-orpEICE",
        "outputId": "22cc228a-28b7-4865-98e3-a868b3639f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hwb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL6Aor8mJrVC",
        "outputId": "09c7356b-d3a6-474b-a20b-8342170cacdb",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hwb\n",
            "  Downloading hwb-0.0.15-py3-none-any.whl.metadata (953 bytes)\n",
            "Collecting bezier (from hwb)\n",
            "  Downloading bezier-2024.6.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from hwb) (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python>=4.1.1->hwb) (2.0.2)\n",
            "Downloading hwb-0.0.15-py3-none-any.whl (8.0 kB)\n",
            "Downloading bezier-2024.6.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bezier, hwb\n",
            "Successfully installed bezier-2024.6.20 hwb-0.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch, torchvision\n",
        "import warnings\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n"
      ],
      "metadata": {
        "id": "FgLnCRVJENIy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm59_ZUtEhp1",
        "outputId": "6785e63b-8eda-4343-9fd9-a754c09552f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/iam-handwriting-word-database.zip'"
      ],
      "metadata": {
        "id": "aIUl8jfKEjdD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_path = \"/content/drive/MyDrive/train_recognition.zip\"\n",
        "extract_to = \"/content/train_recognition\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "eUdmRdAP7xnU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build datasets"
      ],
      "metadata": {
        "id": "MhLlinjvI_No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import re\n",
        "\n",
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, transforms):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _load_file(self, path):\n",
        "      import cv2\n",
        "      import os\n",
        "\n",
        "      if not os.path.exists(path):\n",
        "          raise FileNotFoundError(f\"[ОШИБКА] Файл не найден: {path}\")\n",
        "\n",
        "      image = cv2.imread(path)\n",
        "      if image is None:\n",
        "          raise ValueError(f\"[ОШИБКА] OpenCV не смог загрузить изображение: {path}\")\n",
        "\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        el = self.df.iloc[idx]\n",
        "        file_name = el['image']\n",
        "\n",
        "        image = self._load_file(os.path.join(self.root_dir, file_name))\n",
        "        image = self.transforms(image=image)['image']\n",
        "\n",
        "        return image, el['label']"
      ],
      "metadata": {
        "id": "WxkSzWBiJBwZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from augmixations import HandWrittenBlot\n",
        "from hwb import HandWrittenBlot\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "class AlbuHandWrittenBlot(A.DualTransform):\n",
        "    def __init__(self, hwb, always_apply=False, p=0.5):\n",
        "        super(AlbuHandWrittenBlot, self).__init__(always_apply, p)\n",
        "        self.hwb = hwb\n",
        "\n",
        "    def apply(self, image, **params):\n",
        "        return self.hwb(image)\n",
        "\n",
        "\n",
        "class AlbuPadding(A.DualTransform):\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(AlbuPadding, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, image, **params):\n",
        "        zeros = np.zeros((128, 384, 3))\n",
        "        image = np.concatenate([zeros, image, zeros], axis=0)\n",
        "        return image.astype(np.uint8)"
      ],
      "metadata": {
        "id": "GLMzy4G3JkY4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rectangle_info = {\n",
        "    'x': (None, None),\n",
        "    'y': (None, None),\n",
        "    'h': (60, 100),\n",
        "    'w': (50, 80),\n",
        "}\n",
        "\n",
        "blot_params = {\n",
        "    'incline': (-10, 10),\n",
        "    'intensivity': (0.5, 0.9),\n",
        "    'transparency': (0.05, 0.4),\n",
        "    'count': (1, 3),\n",
        "}\n",
        "\n",
        "blots = HandWrittenBlot(rectangle_info, blot_params)"
      ],
      "metadata": {
        "id": "zH6H2ctSJgv1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "# data_transforms = {\n",
        "#     'train': A.Compose([\n",
        "#               A.Resize(256, 256),\n",
        "#               AlbuHandWrittenBlot(blots, p=0.3),\n",
        "#               A.Rotate(limit=[-7, 7]),\n",
        "#               A.OneOf([\n",
        "#                 A.ToGray(always_apply=True),\n",
        "#                 A.CLAHE(always_apply=True, clip_limit=15),\n",
        "#               ], 0.3),\n",
        "#               ToTensorV2()\n",
        "#           ]),\n",
        "#     'val': A.Compose([\n",
        "#               A.Resize(256, 256),\n",
        "#               ToTensorV2()\n",
        "#           ]),\n",
        "# }\n",
        "\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "data_transforms = {\n",
        "    'train': A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        AlbuHandWrittenBlot(blots, p=0.3),\n",
        "        A.Rotate(limit=[-7, 7]),\n",
        "        A.OneOf([\n",
        "            A.ToGray(always_apply=True),\n",
        "            A.CLAHE(always_apply=True, clip_limit=15),\n",
        "        ], 0.3),\n",
        "        A.Normalize(),            # ← добавлено\n",
        "        ToTensorV2()\n",
        "    ]),\n",
        "    'val': A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.Normalize(),            # ← добавлено\n",
        "        ToTensorV2()\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "dE3-qKnwJiAd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hack_data = pd.read_csv(\"/content/train_recognition/train_recognition/labels.csv\")\n",
        "del hack_data['base_image']\n",
        "hack_data.columns = ['image', 'label']\n",
        "hack_data['image'] = hack_data['image'].apply(lambda x: os.path.join('/content/train_recognition/train_recognition/images', x))\n",
        "hack_data = hack_data[hack_data['label'].apply(lambda x: len(x) >= 4)]\n",
        "hack_data['label'] = hack_data['label'].apply(lambda x: re.search('[а-яА-Я]', x) is not None).astype(int)"
      ],
      "metadata": {
        "id": "RI00Redv7UGk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(hack_data['label'] == 0), sum(hack_data['label'] == 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8EruTUZ8BUD",
        "outputId": "536570b2-d689-4f42-8670-3e2b6aa6d63b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9440, 98944)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hack_data = pd.concat([hack_data[hack_data['label'] == 1][:10000], hack_data[hack_data['label'] == 0][:10000]])\n",
        "len(hack_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhDJab0kBfWA",
        "outputId": "d8afb894-1000-4c43-d6e1-505d2b896a9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19440"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_val = train_test_split(hack_data, test_size=0.1, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "R2nFbZJh74yN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8YogPV68pLu",
        "outputId": "aac4357d-a2ba-458d-8875-fa202e061fc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17496"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = IAMDataset(root_dir='./',\n",
        "                           df=df_train,\n",
        "                           transforms=data_transforms['train'])\n",
        "\n",
        "val_dataset = IAMDataset(root_dir='./',\n",
        "                         df=df_val,\n",
        "                         transforms=data_transforms['val'])"
      ],
      "metadata": {
        "id": "zDAhkM8_87sU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training examples:\", len(train_dataset))\n",
        "print(\"Number of validation examples:\", len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2WQV8oJ8-o5",
        "outputId": "029409e1-3f52-4e9e-c0f2-d1467879bb96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 17496\n",
            "Number of validation examples: 1944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16,)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16,)"
      ],
      "metadata": {
        "id": "Ov1jGQq38_sV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loops"
      ],
      "metadata": {
        "id": "YGb8GFe4IrW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, batch_gen, criterion, optimizer, is_train = True) :\n",
        "  epoch_loss = 0.0\n",
        "  count = 0\n",
        "  accuracy = 0\n",
        "  model.train(is_train)\n",
        "\n",
        "  for input, labels in tqdm(batch_gen) :\n",
        "    input = input.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.set_grad_enabled(is_train) :\n",
        "      pred = model(input)\n",
        "      loss = criterion(pred, labels)\n",
        "      accuracy += torch.sum(torch.max(pred, 1)[1] == labels)\n",
        "\n",
        "      if is_train :\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      count += input.size(0)\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / count, accuracy / count\n"
      ],
      "metadata": {
        "id": "0j7rYe3cIsea"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs) :\n",
        "  loader = {'train' : train_loader, 'test' : test_loader}\n",
        "  loss_history = {'train' : [], 'test' : []}\n",
        "  acc_history = {'train' : [], 'test' : []}\n",
        "\n",
        "  for epoch in range(num_epochs) :\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'test'] :\n",
        "      epoch_loss, epoch_acc = train_epoch(model, loader[phase], criterion, optimizer, phase == 'train')\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "      loss_history[phase].append(epoch_loss)\n",
        "      acc_history[phase].append(epoch_acc)\n",
        "\n",
        "    print()\n",
        "\n",
        "  return loss_history, acc_history"
      ],
      "metadata": {
        "id": "9pdurY6XIt7I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "gJkmIDMaIIK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "id": "uj2eG0qjIJ5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456f0dc5-5a92-4a18-e704-959347511e45"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 2),\n",
        ")"
      ],
      "metadata": {
        "id": "HVjcqkZ3Imny"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)"
      ],
      "metadata": {
        "id": "_bJ9S6mDIwe-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train, acc_train = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Ky6sLi88A-",
        "outputId": "c0dc6f6e-33cf-4c86-a76a-8e1a2788a8d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2187/2187 [04:13<00:00,  8.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.0190 Acc: 0.9471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:11<00:00, 21.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Loss: 0.0097 Acc: 0.9722\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2187/2187 [04:14<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.0095 Acc: 0.9745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:10<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Loss: 0.0106 Acc: 0.9681\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2187/2187 [04:12<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.0084 Acc: 0.9767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:10<00:00, 22.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Loss: 0.0020 Acc: 0.9949\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/language_classification_model/model.pt\")"
      ],
      "metadata": {
        "id": "IzpMsiIu9fgx"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}