{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "548d1a24",
      "metadata": {
        "id": "548d1a24"
      },
      "source": [
        "# Распознавание текста\n",
        "\n",
        "## CRNN+CTC loss baseline\n",
        "\n",
        "В данном ноутбуке представлен baseline модели распознавания текста с помощью CRNN модели и CTC loss. Вы можете добавить новые аугментации или изменить структуру данной модели, или же попробовать совершенно новую архитектуру."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a804d024",
      "metadata": {
        "id": "a804d024"
      },
      "source": [
        "# 0. Установка и подгрузука библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4LqTxz3sePE5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4LqTxz3sePE5",
        "outputId": "760f9d22-1650-42be-ffc5-c5b9e99245f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-n15qc6sn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-n15qc6sn\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 536dc9d527074e3b15df5f6677ffe1f4e104a4ab\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.4.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision --quiet\n",
        "!pip install -U git+https://github.com/facebookresearch/detectron2.git\n",
        "!pip install opencv-python matplotlib pandas scikit-learn --quie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dcce067f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dcce067f",
        "outputId": "5d54e873-c3d1-45d2-d4e1-740cada13f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.20.3\n",
            "  Using cached numpy-1.20.3.zip (7.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numpy)\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.5.2.52 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84, 4.11.0.86)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: matplotlib==3.4.2 in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (2.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.4.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.4.2) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        " !pip install numpy==1.20.3\n",
        " !pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        " !pip install opencv-python==4.5.2.52\n",
        " !pip install matplotlib==3.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ee595a",
      "metadata": {
        "id": "63ee595a"
      },
      "source": [
        "Установка библиотек, под которым запускается данный бейзлайн."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BakiO_qxSjot",
        "outputId": "435fc487-d35c-445d-b52f-436c6ae59ce7"
      },
      "id": "BakiO_qxSjot",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4dc81cd6",
      "metadata": {
        "id": "4dc81cd6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from jiwer import wer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5e66674",
      "metadata": {
        "id": "b5e66674"
      },
      "source": [
        "## 1. Разделим трейн датасет на обучающую и валидационную подвыборки\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2b5a075",
      "metadata": {
        "id": "d2b5a075"
      },
      "source": [
        "Сначала преобразуем таблицу (в которой есть колонка base_image) в `labels.json` - это формат из второго этапа олимпиады, для которого составлялся бейзлайн. По сути это просто словарь из колонок 'file_name' и 'text'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3a5fcf69",
      "metadata": {
        "id": "3a5fcf69"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "p_hc3GFa-Mta",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_hc3GFa-Mta",
        "outputId": "79b0bd2b-f2ea-4f4b-ce94-66db52008365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8b3YF9tgcZlQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3YF9tgcZlQ",
        "outputId": "9ca71f0f-6582-4135-a8c0-6b7c83eda8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итоговая длина train_data: 1002\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df_path = '/content/drive/MyDrive/train_recognition_small'\n",
        "train_csv = pd.read_csv(os.path.join(df_path, 'labels.csv')).head(2002)\n",
        "images_folder = os.path.join(df_path, 'images')\n",
        "available_files = set(os.listdir(images_folder))\n",
        "train_csv = train_csv[train_csv['file_name'].isin(available_files)].reset_index(drop=True)\n",
        "train_data = dict(train_csv[['file_name', 'text']].values)\n",
        "print(\"Итоговая длина train_data:\", len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "37b27c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37b27c0a",
        "outputId": "48e03c0f-4bde-4002-d80c-027d58af0122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train len 1002\n",
            "train len after split 751\n",
            "val len after split 251\n"
          ]
        }
      ],
      "source": [
        "train_data = [(k, v) for k, v in train_data.items()]\n",
        "print('train len', len(train_data))\n",
        "\n",
        "split_coef = 0.75\n",
        "train_len = int(len(train_data)*split_coef)\n",
        "\n",
        "train_data_splitted = train_data[:train_len]\n",
        "val_data_splitted = train_data[train_len:]\n",
        "\n",
        "print('train len after split', len(train_data_splitted))\n",
        "print('val len after split', len(val_data_splitted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "8eacdebf",
      "metadata": {
        "collapsed": true,
        "id": "8eacdebf"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/train_recognition_small/train_labels_splitted.json', 'w') as f:\n",
        "    json.dump(dict(train_data_splitted), f)\n",
        "\n",
        "with open('/content/drive/MyDrive/train_recognition_small/val_labels_splitted.json', 'w') as f:\n",
        "    json.dump(dict(val_data_splitted), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "270c0c76",
      "metadata": {
        "id": "270c0c76"
      },
      "source": [
        "## 2. Зададим параметры обучения\n",
        "\n",
        "Здесь мы можем поправить конфиги обучения - задать размер батча, количество эпох, размер входных изображений, а также установить пути к датасетам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7109653",
      "metadata": {
        "id": "e7109653"
      },
      "outputs": [],
      "source": [
        "alphabet = ''.join(sorted(list(set(''.join(train_csv['text'].values)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6d8a5e43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6d8a5e43",
        "outputId": "ff47964b-ca3a-449c-ab9a-e644c12ec157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' !\"(),-.012345:?АБВДЕЗИКМНОПРСТУХЧЭЯабвгдежзийклмнопрстуфхцчшщъыьэюяё'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "3539fc96",
      "metadata": {
        "id": "3539fc96"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "config_json = {\n",
        "    \"alphabet\": ''' !\"%\\'()*+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPRSTUVWXY[]_abcdefghijklmnopqrstuvwxyz|}ЁАБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяё№''',\n",
        "    \"save_dir\": \"experiments/test\",\n",
        "    \"num_epochs\": 120,\n",
        "    \"image\": {\n",
        "        \"width\": 256,\n",
        "        \"height\": 32\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"root_path\": \"/content/drive/MyDrive/train_recognition_small/images/\",\n",
        "        \"json_path\": \"/content/drive/MyDrive/train_recognition_small/train_labels_splitted.json\",\n",
        "        \"batch_size\": 64\n",
        "    },\n",
        "    \"val\": {\n",
        "        \"root_path\": \"/content/drive/MyDrive/train_recognition_small/images/\",\n",
        "        \"json_path\": \"/content/drive/MyDrive/train_recognition_small/val_labels_splitted.json\",\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8e2ddbfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2ddbfc",
        "outputId": "e404d580-20fd-455e-927e-eb3c6749e90f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83e04f96",
      "metadata": {
        "id": "83e04f96"
      },
      "source": [
        "## 3. Теперь определим класс датасета (torch.utils.data.Dataset) и другие вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b976c163",
      "metadata": {
        "id": "b976c163"
      },
      "outputs": [],
      "source": [
        "# функция которая помогает объединять картинки и таргет-текст в батч\n",
        "def collate_fn(batch):\n",
        "    images, texts, enc_texts = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    text_lens = torch.LongTensor([len(text) for text in texts])\n",
        "    enc_pad_texts = pad_sequence(enc_texts, batch_first=True, padding_value=0)\n",
        "    return images, texts, enc_pad_texts, text_lens\n",
        "\n",
        "\n",
        "def get_data_loader(\n",
        "    transforms, json_path, root_path, tokenizer, batch_size, drop_last\n",
        "):\n",
        "    dataset = OCRDataset(json_path, root_path, tokenizer, transforms)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=8,\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, json_path, root_path, tokenizer, transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        self.data_len = len(data)\n",
        "\n",
        "        self.img_paths = []\n",
        "        self.texts = []\n",
        "        for img_name, text in data.items():\n",
        "            self.img_paths.append(os.path.join(root_path, img_name))\n",
        "            self.texts.append(text)\n",
        "        self.enc_texts = tokenizer.encode(self.texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        # print(\"Путь к изображению:\", img_path)\n",
        "        text = self.texts[idx]\n",
        "        enc_text = torch.LongTensor(self.enc_texts[idx])\n",
        "        image = cv2.imread(img_path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, text, enc_text\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b28fdb5",
      "metadata": {
        "id": "2b28fdb5"
      },
      "source": [
        "## 4. Здесь определен Токенайзер - вспопогательный класс, который преобразует текст в числа\n",
        "\n",
        "Разметка-текст с картинок преобразуется в числовое представление, на которых модель может учиться. Также может преобразовывать числовое предсказание модели обратно в текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d1648058",
      "metadata": {
        "id": "d1648058"
      },
      "outputs": [],
      "source": [
        "OOV_TOKEN = '<OOV>'\n",
        "CTC_BLANK = '<BLANK>'\n",
        "\n",
        "\n",
        "def get_char_map(alphabet):\n",
        "    \"\"\"Make from string alphabet character2int dict.\n",
        "    Add BLANK char fro CTC loss and OOV char for out of vocabulary symbols.\"\"\"\n",
        "    char_map = {value: idx + 2 for (idx, value) in enumerate(alphabet)}\n",
        "    char_map[CTC_BLANK] = 0\n",
        "    char_map[OOV_TOKEN] = 1\n",
        "    return char_map\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    \"\"\"Class for encoding and decoding string word to sequence of int\n",
        "    (and vice versa) using alphabet.\"\"\"\n",
        "\n",
        "    def __init__(self, alphabet):\n",
        "        self.char_map = get_char_map(alphabet)\n",
        "        self.rev_char_map = {val: key for key, val in self.char_map.items()}\n",
        "\n",
        "    def encode(self, word_list):\n",
        "        \"\"\"Returns a list of encoded words (int).\"\"\"\n",
        "        enc_words = []\n",
        "        for word in word_list:\n",
        "            enc_words.append(\n",
        "                [self.char_map[char] if char in self.char_map\n",
        "                 else self.char_map[OOV_TOKEN]\n",
        "                 for char in word]\n",
        "            )\n",
        "        return enc_words\n",
        "\n",
        "    def get_num_chars(self):\n",
        "        return len(self.char_map)\n",
        "\n",
        "    def decode(self, enc_word_list):\n",
        "        \"\"\"Returns a list of words (str) after removing blanks and collapsing\n",
        "        repeating characters. Also skip out of vocabulary token.\"\"\"\n",
        "        dec_words = []\n",
        "        for word in enc_word_list:\n",
        "            word_chars = ''\n",
        "            for idx, char_enc in enumerate(word):\n",
        "                # skip if blank symbol, oov token or repeated characters\n",
        "                if (\n",
        "                    char_enc != self.char_map[OOV_TOKEN]\n",
        "                    and char_enc != self.char_map[CTC_BLANK]\n",
        "                    # idx > 0 to avoid selecting [-1] item\n",
        "                    and not (idx > 0 and char_enc == word[idx - 1])\n",
        "                ):\n",
        "                    word_chars += self.rev_char_map[char_enc]\n",
        "            dec_words.append(word_chars)\n",
        "        return dec_words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c6df21",
      "metadata": {
        "id": "89c6df21"
      },
      "source": [
        "## 5. Accuracy в качестве метрики\n",
        "\n",
        "Accuracy измеряет долю предсказанных строк текста, которые полностью совпадают с таргет текстом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "588929f3",
      "metadata": {
        "id": "588929f3"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(y_true, y_pred):\n",
        "    scores = []\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        scores.append(true == pred)\n",
        "    avg_score = np.mean(scores)\n",
        "    return avg_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import cer\n",
        "\n",
        "def get_cer(true_texts, pred_texts):\n",
        "    total_cer = 0.0\n",
        "    for true, pred in zip(true_texts, pred_texts):\n",
        "        total_cer += cer(true, pred)\n",
        "    return total_cer / len(true_texts)"
      ],
      "metadata": {
        "id": "Vl1V6GkTTdGo"
      },
      "id": "Vl1V6GkTTdGo",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3bb94641",
      "metadata": {
        "id": "3bb94641"
      },
      "source": [
        "## 6. Аугментации\n",
        "\n",
        "Здесь мы задаем базовые аугментации для модели. Вы можете написать свои или использовать готовые библиотеки типа albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "615419c3",
      "metadata": {
        "id": "615419c3"
      },
      "outputs": [],
      "source": [
        "class Normalize:\n",
        "    def __call__(self, img):\n",
        "        img = img.astype(np.float32) / 255\n",
        "        return img\n",
        "\n",
        "\n",
        "class ToTensor:\n",
        "    def __call__(self, arr):\n",
        "        arr = torch.from_numpy(arr)\n",
        "        return arr\n",
        "\n",
        "\n",
        "class MoveChannels:\n",
        "    \"\"\"Move the channel axis to the zero position as required in pytorch.\"\"\"\n",
        "\n",
        "    def __init__(self, to_channels_first=True):\n",
        "        self.to_channels_first = to_channels_first\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if self.to_channels_first:\n",
        "            return np.moveaxis(image, -1, 0)\n",
        "        else:\n",
        "            return np.moveaxis(image, 0, -1)\n",
        "\n",
        "\n",
        "class ImageResize:\n",
        "    def __init__(self, height, width):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if image is None:\n",
        "          raise FileNotFoundError(\"OpenCV не смог загрузить изображение (None)\")\n",
        "        image = cv2.resize(image, (self.width, self.height),\n",
        "                           interpolation=cv2.INTER_LINEAR)\n",
        "        return image\n",
        "\n",
        "\n",
        "\n",
        "def get_train_transforms(height, width):\n",
        "    transforms = torchvision.transforms.Compose([\n",
        "        ImageResize(height, width),\n",
        "        MoveChannels(to_channels_first=True),\n",
        "        Normalize(),\n",
        "        ToTensor()\n",
        "    ])\n",
        "    return transforms\n",
        "\n",
        "\n",
        "def get_val_transforms(height, width):\n",
        "    transforms = torchvision.transforms.Compose([\n",
        "        ImageResize(height, width),\n",
        "        MoveChannels(to_channels_first=True),\n",
        "        Normalize(),\n",
        "        ToTensor()\n",
        "    ])\n",
        "    return transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda2a878",
      "metadata": {
        "id": "dda2a878"
      },
      "source": [
        "## 7. Здесь определяем саму модель - CRNN\n",
        "\n",
        "Подробнее об архитектуре можно почитать в статье https://arxiv.org/abs/1507.05717"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5d85e1d0",
      "metadata": {
        "id": "5d85e1d0"
      },
      "outputs": [],
      "source": [
        "def get_resnet34_backbone(pretrained=True):\n",
        "    m = torchvision.models.resnet34(pretrained=True)\n",
        "    input_conv = nn.Conv2d(3, 64, 7, 1, 3)\n",
        "    blocks = [input_conv, m.bn1, m.relu,\n",
        "              m.maxpool, m.layer1, m.layer2, m.layer3]\n",
        "    return nn.Sequential(*blocks)\n",
        "\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size, hidden_size, num_layers,\n",
        "            dropout=dropout, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self, number_class_symbols, time_feature_count=256, lstm_hidden=256,\n",
        "        lstm_len=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = get_resnet34_backbone(pretrained=True)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(\n",
        "            (time_feature_count, time_feature_count))\n",
        "        self.bilstm = BiLSTM(time_feature_count, lstm_hidden, lstm_len)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_hidden * 2, time_feature_count),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(time_feature_count, number_class_symbols)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.view(b, c * h, w)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.bilstm(x)\n",
        "        x = self.classifier(x)\n",
        "        x = nn.functional.log_softmax(x, dim=2).permute(1, 0, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b579f5a",
      "metadata": {
        "id": "3b579f5a"
      },
      "source": [
        "## 8. Переходим к самому скрипту обучения - циклы трейна и валидации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d38b9c8b",
      "metadata": {
        "id": "d38b9c8b"
      },
      "outputs": [],
      "source": [
        "# def val_loop(data_loader, model, tokenizer, device):\n",
        "#     acc_avg = AverageMeter()\n",
        "#     #for images, texts, _, _ in data_loader:\n",
        "#     #    batch_size = len(texts)\n",
        "#     #    text_preds = predict(images, model, tokenizer, device)\n",
        "#     #    acc_avg.update(get_accuracy(texts, text_preds), batch_size)\n",
        "#     #print(f'Validation, acc: {acc_avg.avg:.4f}')\n",
        "#     #return acc_avg.avg\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():  #Выключаем градиенты\n",
        "#         for images, texts, _, _ in data_loader:\n",
        "#             batch_size = len(texts)\n",
        "#             text_preds = predict(images, model, tokenizer, device)\n",
        "#             acc_avg.update(get_accuracy(texts, text_preds), batch_size)\n",
        "#     print(f'Validation, acc: {acc_avg.avg:.4f}')\n",
        "#     return acc_avg.avg\n",
        "\n",
        "def val_loop(data_loader, model, tokenizer, device):\n",
        "    acc_avg = AverageMeter()\n",
        "    cer_total = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, texts, _, _ in data_loader:\n",
        "            batch_size = len(texts)\n",
        "            text_preds = predict(images, model, tokenizer, device)\n",
        "\n",
        "            acc = get_accuracy(texts, text_preds)\n",
        "            acc_avg.update(acc, batch_size)\n",
        "\n",
        "            cer_total += get_cer(texts, text_preds) * batch_size\n",
        "            total_samples += batch_size\n",
        "\n",
        "    cer_avg = cer_total / total_samples\n",
        "    print(f'Validation, acc: {acc_avg.avg:.4f}, CER: {cer_avg:.4f}')\n",
        "    return acc_avg.avg, cer_avg\n",
        "\n",
        "\n",
        "# def train_loop(data_loader, model, criterion, optimizer, epoch):\n",
        "#     loss_avg = AverageMeter()\n",
        "#     model.train()\n",
        "#     for images, texts, enc_pad_texts, text_lens in data_loader:\n",
        "#         model.zero_grad()\n",
        "#         images = images.to(DEVICE)\n",
        "#         batch_size = len(texts)\n",
        "#         output = model(images)\n",
        "#         output_lenghts = torch.full(\n",
        "#             size=(output.size(1),),\n",
        "#             fill_value=output.size(0),\n",
        "#             dtype=torch.long\n",
        "#         )\n",
        "#         loss = criterion(output, enc_pad_texts, output_lenghts, text_lens)\n",
        "#         loss_avg.update(loss.item(), batch_size)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
        "#         optimizer.step()\n",
        "#     for param_group in optimizer.param_groups:\n",
        "#         lr = param_group['lr']\n",
        "#     print(f'\\nEpoch {epoch}, Loss: {loss_avg.avg:.5f}, LR: {lr:.7f}')\n",
        "#     return loss_avg.avg\n",
        "\n",
        "def train_loop(data_loader, model, criterion, optimizer, epoch):\n",
        "    loss_avg = AverageMeter()\n",
        "    model.train()\n",
        "    for images, texts, enc_pad_texts, text_lens in data_loader:\n",
        "        model.zero_grad()\n",
        "        images = images.to(DEVICE)\n",
        "        batch_size = len(texts)\n",
        "\n",
        "        output = model(images)\n",
        "        output_lengths = torch.full(\n",
        "            size=(output.size(1),),\n",
        "            fill_value=output.size(0),\n",
        "            dtype=torch.long\n",
        "        )\n",
        "\n",
        "        loss = criterion(output, enc_pad_texts, output_lengths, text_lens)\n",
        "        loss_avg.update(loss.item(), batch_size)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
        "        optimizer.step()\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr = param_group['lr']\n",
        "    print(f'\\nEpoch {epoch}, Loss: {loss_avg.avg:.5f}, LR: {lr:.7f}')\n",
        "    return loss_avg.avg\n",
        "\n",
        "\n",
        "# def predict(images, model, tokenizer, device):\n",
        "#     model.eval()\n",
        "#     images = images.to(device)\n",
        "#     with torch.no_grad():\n",
        "#         output = model(images)\n",
        "#     pred = torch.argmax(output.detach().cpu(), -1).permute(1, 0).numpy()\n",
        "#     text_preds = tokenizer.decode(pred)\n",
        "#     return text_preds\n",
        "\n",
        "def predict(images, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(images)  # [T, B, C]\n",
        "    logits = output.detach().cpu()\n",
        "    pred_indices = torch.argmax(logits, dim=-1)  # [T, B]\n",
        "    pred_indices = pred_indices.permute(1, 0).numpy()  # [B, T]\n",
        "\n",
        "    # CTC decoding: remove duplicates and blanks (index 0 assumed to be blank)\n",
        "    decoded = []\n",
        "    for seq in pred_indices:\n",
        "        prev = -1\n",
        "        out = []\n",
        "        for idx in seq:\n",
        "            if idx != prev and idx != 0:\n",
        "                out.append(idx)\n",
        "            prev = idx\n",
        "        decoded.append(tokenizer.decode([out]))\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def get_loaders(tokenizer, config):\n",
        "    train_transforms = get_train_transforms(\n",
        "        height=config['image']['height'],\n",
        "        width=config['image']['width']\n",
        "    )\n",
        "    train_loader = get_data_loader(\n",
        "        json_path=config['train']['json_path'],\n",
        "        root_path=config['train']['root_path'],\n",
        "        transforms=train_transforms,\n",
        "        tokenizer=tokenizer,\n",
        "        batch_size=config['train']['batch_size'],\n",
        "        drop_last=True\n",
        "    )\n",
        "    val_transforms = get_val_transforms(\n",
        "        height=config['image']['height'],\n",
        "        width=config['image']['width']\n",
        "    )\n",
        "    val_loader = get_data_loader(\n",
        "        transforms=val_transforms,\n",
        "        json_path=config['val']['json_path'],\n",
        "        root_path=config['val']['root_path'],\n",
        "        tokenizer=tokenizer,\n",
        "        batch_size=config['val']['batch_size'],\n",
        "        drop_last=False\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "# def train(config):\n",
        "#     tokenizer = Tokenizer(config['alphabet'])\n",
        "#     os.makedirs(config['save_dir'], exist_ok=True)\n",
        "#     train_loader, val_loader = get_loaders(tokenizer, config)\n",
        "\n",
        "#     model = CRNN(number_class_symbols=tokenizer.get_num_chars())\n",
        "#     model.to(DEVICE)\n",
        "\n",
        "#     criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=0.001,\n",
        "#                                   weight_decay=0.01)\n",
        "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#         optimizer=optimizer, mode='max', factor=0.5, patience=15)\n",
        "#     best_acc = -np.inf\n",
        "#     acc_avg = val_loop(val_loader, model, tokenizer, DEVICE)\n",
        "#     for epoch in range(config['num_epochs']):\n",
        "#         loss_avg = train_loop(train_loader, model, criterion, optimizer, epoch)\n",
        "#         acc_avg = val_loop(val_loader, model, tokenizer, DEVICE)\n",
        "#         scheduler.step(acc_avg)\n",
        "#         if acc_avg > best_acc:\n",
        "#             best_acc = acc_avg\n",
        "#             model_save_path = os.path.join(\n",
        "#                 config['save_dir'], f'model-{epoch}-{acc_avg:.4f}.ckpt')\n",
        "#             torch.save(model.state_dict(), model_save_path)\n",
        "#             print('Model weights saved')\n",
        "\n",
        "\n",
        "def train(config):\n",
        "    tokenizer = Tokenizer(config['alphabet'])\n",
        "    os.makedirs(config['save_dir'], exist_ok=True)\n",
        "    train_loader, val_loader = get_loaders(tokenizer, config)\n",
        "\n",
        "    model = CRNN(number_class_symbols=tokenizer.get_num_chars())\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer=optimizer, mode='max', factor=0.5, patience=15)\n",
        "\n",
        "    best_acc = -np.inf\n",
        "    history = []\n",
        "\n",
        "    acc_avg, cer_avg = val_loop(val_loader, model, tokenizer, DEVICE)  # ← обновлённый val_loop\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        loss_avg = train_loop(train_loader, model, criterion, optimizer, epoch)\n",
        "        acc_avg, cer_avg = val_loop(val_loader, model, tokenizer, DEVICE)\n",
        "        scheduler.step(acc_avg)\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss_avg,\n",
        "            \"accuracy\": acc_avg,\n",
        "            \"cer\": cer_avg\n",
        "        })\n",
        "\n",
        "        if acc_avg > best_acc:\n",
        "            best_acc = acc_avg\n",
        "            model_save_path = os.path.join(\n",
        "                config['save_dir'], f'model-{epoch}-{acc_avg:.4f}.ckpt')\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print('Model weights saved')\n",
        "\n",
        "    # === Визуализация после обучения ===\n",
        "    df_history = pd.DataFrame(history)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_history[\"epoch\"].to_numpy(), df_history[\"accuracy\"].to_numpy(), label=\"Accuracy\")\n",
        "    plt.plot(df_history[\"epoch\"].to_numpy(), df_history[\"cer\"].to_numpy(), label=\"CER\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.title(\"Validation Accuracy & CER\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # График Loss\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_history[\"epoch\"].to_numpy(), df_history[\"loss\"].to_numpy(), color=\"red\", label=\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    #     # === Сохранение истории метрик в CSV ===\n",
        "    # history_path = os.path.join(config['save_dir'], \"training_history.csv\")\n",
        "    # df_history.to_csv(history_path, index=False)\n",
        "    # print(f\"\\n📁 История обучения сохранена: {history_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "702a7f74",
      "metadata": {
        "id": "702a7f74"
      },
      "source": [
        "## 9. Запускаем обучение!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.Inf = np.inf"
      ],
      "metadata": {
        "id": "eWupQatLYu29"
      },
      "id": "eWupQatLYu29",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "2623aea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "2623aea6",
        "scrolled": true,
        "outputId": "edbd9e4f-2a5a-4ec5-88b3-39c6eec901ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation, acc: 0.0000, CER: 1.2776\n",
            "\n",
            "Epoch 0, Loss: 143.81783, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "Model weights saved\n",
            "\n",
            "Epoch 1, Loss: 4.64555, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 2, Loss: 4.25414, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 3, Loss: 4.06039, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 4, Loss: 3.97796, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 5, Loss: 3.99695, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 6, Loss: 3.87821, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 7, Loss: 3.85231, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 1.0000\n",
            "\n",
            "Epoch 8, Loss: 3.78274, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9630\n",
            "\n",
            "Epoch 9, Loss: 3.73292, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9062\n",
            "\n",
            "Epoch 10, Loss: 3.75127, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9062\n",
            "\n",
            "Epoch 11, Loss: 3.68237, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9062\n",
            "\n",
            "Epoch 12, Loss: 3.65992, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9069\n",
            "\n",
            "Epoch 13, Loss: 3.61210, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9172\n",
            "\n",
            "Epoch 14, Loss: 3.57941, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9036\n",
            "\n",
            "Epoch 15, Loss: 3.54803, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9134\n",
            "\n",
            "Epoch 16, Loss: 3.53676, LR: 0.0010000\n",
            "Validation, acc: 0.0000, CER: 0.9062\n",
            "\n",
            "Epoch 17, Loss: 3.46933, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.9062\n",
            "\n",
            "Epoch 18, Loss: 3.42833, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.9092\n",
            "\n",
            "Epoch 19, Loss: 3.38797, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8796\n",
            "\n",
            "Epoch 20, Loss: 3.37943, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8888\n",
            "\n",
            "Epoch 21, Loss: 3.35262, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8662\n",
            "\n",
            "Epoch 22, Loss: 3.39485, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8608\n",
            "\n",
            "Epoch 23, Loss: 3.40542, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8679\n",
            "\n",
            "Epoch 24, Loss: 3.40924, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8582\n",
            "\n",
            "Epoch 25, Loss: 3.35720, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8674\n",
            "\n",
            "Epoch 26, Loss: 3.33506, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8607\n",
            "\n",
            "Epoch 27, Loss: 3.33945, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8693\n",
            "\n",
            "Epoch 28, Loss: 3.28624, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8707\n",
            "\n",
            "Epoch 29, Loss: 3.26786, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8688\n",
            "\n",
            "Epoch 30, Loss: 3.30751, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8741\n",
            "\n",
            "Epoch 31, Loss: 3.29456, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8554\n",
            "\n",
            "Epoch 32, Loss: 3.24629, LR: 0.0005000\n",
            "Validation, acc: 0.0000, CER: 0.8555\n",
            "\n",
            "Epoch 33, Loss: 3.23020, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8500\n",
            "\n",
            "Epoch 34, Loss: 3.17834, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8611\n",
            "\n",
            "Epoch 35, Loss: 3.15548, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8704\n",
            "\n",
            "Epoch 36, Loss: 3.13010, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8612\n",
            "\n",
            "Epoch 37, Loss: 3.12450, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8601\n",
            "\n",
            "Epoch 38, Loss: 3.10180, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8678\n",
            "\n",
            "Epoch 39, Loss: 3.08070, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8553\n",
            "\n",
            "Epoch 40, Loss: 3.06256, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8518\n",
            "\n",
            "Epoch 41, Loss: 3.05718, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8580\n",
            "\n",
            "Epoch 42, Loss: 3.03729, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8452\n",
            "\n",
            "Epoch 43, Loss: 3.01380, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8614\n",
            "\n",
            "Epoch 44, Loss: 2.98852, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8602\n",
            "\n",
            "Epoch 45, Loss: 2.95650, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8653\n",
            "\n",
            "Epoch 46, Loss: 2.93855, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8600\n",
            "\n",
            "Epoch 47, Loss: 2.93020, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8545\n",
            "\n",
            "Epoch 48, Loss: 2.93234, LR: 0.0002500\n",
            "Validation, acc: 0.0000, CER: 0.8643\n",
            "\n",
            "Epoch 49, Loss: 2.91953, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8673\n",
            "\n",
            "Epoch 50, Loss: 2.87351, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8441\n",
            "\n",
            "Epoch 51, Loss: 2.83468, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8588\n",
            "\n",
            "Epoch 52, Loss: 2.81915, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8514\n",
            "\n",
            "Epoch 53, Loss: 2.78476, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8582\n",
            "\n",
            "Epoch 54, Loss: 2.76879, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8458\n",
            "\n",
            "Epoch 55, Loss: 2.75863, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8527\n",
            "\n",
            "Epoch 56, Loss: 2.72673, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8545\n",
            "\n",
            "Epoch 57, Loss: 2.72094, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8567\n",
            "\n",
            "Epoch 58, Loss: 2.72815, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8491\n",
            "\n",
            "Epoch 59, Loss: 2.70225, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8608\n",
            "\n",
            "Epoch 60, Loss: 2.69263, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8656\n",
            "\n",
            "Epoch 61, Loss: 2.67654, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8453\n",
            "\n",
            "Epoch 62, Loss: 2.66942, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8448\n",
            "\n",
            "Epoch 63, Loss: 2.64795, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8615\n",
            "\n",
            "Epoch 64, Loss: 2.63826, LR: 0.0001250\n",
            "Validation, acc: 0.0000, CER: 0.8393\n",
            "\n",
            "Epoch 65, Loss: 2.60815, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8442\n",
            "\n",
            "Epoch 66, Loss: 2.58736, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8473\n",
            "\n",
            "Epoch 67, Loss: 2.55845, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8453\n",
            "\n",
            "Epoch 68, Loss: 2.54887, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8527\n",
            "\n",
            "Epoch 69, Loss: 2.53020, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8544\n",
            "\n",
            "Epoch 70, Loss: 2.52062, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8449\n",
            "\n",
            "Epoch 71, Loss: 2.52085, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8541\n",
            "\n",
            "Epoch 72, Loss: 2.50241, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8501\n",
            "\n",
            "Epoch 73, Loss: 2.48354, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8404\n",
            "\n",
            "Epoch 74, Loss: 2.47954, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8534\n",
            "\n",
            "Epoch 75, Loss: 2.47295, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8496\n",
            "\n",
            "Epoch 76, Loss: 2.46978, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8519\n",
            "\n",
            "Epoch 77, Loss: 2.45400, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8511\n",
            "\n",
            "Epoch 78, Loss: 2.43658, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8523\n",
            "\n",
            "Epoch 79, Loss: 2.43850, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8569\n",
            "\n",
            "Epoch 80, Loss: 2.41782, LR: 0.0000625\n",
            "Validation, acc: 0.0000, CER: 0.8470\n",
            "\n",
            "Epoch 81, Loss: 2.41475, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8441\n",
            "\n",
            "Epoch 82, Loss: 2.39659, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8497\n",
            "\n",
            "Epoch 83, Loss: 2.38654, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8525\n",
            "\n",
            "Epoch 84, Loss: 2.37794, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8520\n",
            "\n",
            "Epoch 85, Loss: 2.37779, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8482\n",
            "\n",
            "Epoch 86, Loss: 2.37081, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8519\n",
            "\n",
            "Epoch 87, Loss: 2.36442, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8518\n",
            "\n",
            "Epoch 88, Loss: 2.35677, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8521\n",
            "\n",
            "Epoch 89, Loss: 2.35571, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8504\n",
            "\n",
            "Epoch 90, Loss: 2.35143, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8505\n",
            "\n",
            "Epoch 91, Loss: 2.34384, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8510\n",
            "\n",
            "Epoch 92, Loss: 2.33599, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8579\n",
            "\n",
            "Epoch 93, Loss: 2.33709, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8523\n",
            "\n",
            "Epoch 94, Loss: 2.32882, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8476\n",
            "\n",
            "Epoch 95, Loss: 2.32456, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8507\n",
            "\n",
            "Epoch 96, Loss: 2.31249, LR: 0.0000313\n",
            "Validation, acc: 0.0000, CER: 0.8543\n",
            "\n",
            "Epoch 97, Loss: 2.31981, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8513\n",
            "\n",
            "Epoch 98, Loss: 2.30070, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8518\n",
            "\n",
            "Epoch 99, Loss: 2.30220, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8496\n",
            "\n",
            "Epoch 100, Loss: 2.29149, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8537\n",
            "\n",
            "Epoch 101, Loss: 2.29211, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8469\n",
            "\n",
            "Epoch 102, Loss: 2.29779, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8506\n",
            "\n",
            "Epoch 103, Loss: 2.28597, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8473\n",
            "\n",
            "Epoch 104, Loss: 2.27929, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8464\n",
            "\n",
            "Epoch 105, Loss: 2.28347, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8506\n",
            "\n",
            "Epoch 106, Loss: 2.28301, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8492\n",
            "\n",
            "Epoch 107, Loss: 2.27605, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8495\n",
            "\n",
            "Epoch 108, Loss: 2.26079, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8479\n",
            "\n",
            "Epoch 109, Loss: 2.27227, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8516\n",
            "\n",
            "Epoch 110, Loss: 2.26626, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8486\n",
            "\n",
            "Epoch 111, Loss: 2.25473, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8478\n",
            "\n",
            "Epoch 112, Loss: 2.26879, LR: 0.0000156\n",
            "Validation, acc: 0.0000, CER: 0.8446\n",
            "\n",
            "Epoch 113, Loss: 2.25327, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8469\n",
            "\n",
            "Epoch 114, Loss: 2.25805, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8488\n",
            "\n",
            "Epoch 115, Loss: 2.25728, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8463\n",
            "\n",
            "Epoch 116, Loss: 2.24895, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8466\n",
            "\n",
            "Epoch 117, Loss: 2.24464, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8454\n",
            "\n",
            "Epoch 118, Loss: 2.24720, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8438\n",
            "\n",
            "Epoch 119, Loss: 2.24501, LR: 0.0000078\n",
            "Validation, acc: 0.0000, CER: 0.8428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📁 История обучения сохранена: experiments/test/training_history.csv\n"
          ]
        }
      ],
      "source": [
        "train(config_json)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {config['save_dir'] + '/logs'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "x8N1V1ZtQ__6",
        "outputId": "24173d6f-b193-4f8c-e019-9bd8487723c4"
      },
      "id": "x8N1V1ZtQ__6",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 2).\n",
              "Contents of stderr:\n",
              "2025-05-06 17:11:05.323473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
              "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
              "E0000 00:00:1746551465.345594   42605 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
              "E0000 00:00:1746551465.351996   42605 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
              "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
              "                   [--host ADDR] [--bind_all] [--port PORT]\n",
              "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
              "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
              "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
              "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
              "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
              "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
              "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
              "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
              "                   [--reload_multifile BOOL]\n",
              "                   [--reload_multifile_inactive_secs SECONDS]\n",
              "                   [--generic_data TYPE]\n",
              "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
              "                   [--detect_file_replacement BOOL]\n",
              "                   {serve} ...\n",
              "tensorboard: error: argument {serve}: invalid choice: '+' (choose from 'serve')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29f4656d",
      "metadata": {
        "id": "29f4656d"
      },
      "source": [
        "## 10. Создание предсказаний для public-датасета\n",
        "\n",
        "Сначала определим класс для создания предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d187224",
      "metadata": {
        "id": "5d187224"
      },
      "outputs": [],
      "source": [
        "class InferenceTransform:\n",
        "    def __init__(self, height, width):\n",
        "        self.transforms = get_val_transforms(height, width)\n",
        "\n",
        "    def __call__(self, images):\n",
        "        transformed_images = []\n",
        "        for image in images:\n",
        "            image = self.transforms(image)\n",
        "            transformed_images.append(image)\n",
        "        transformed_tensor = torch.stack(transformed_images, 0)\n",
        "        return transformed_tensor\n",
        "\n",
        "\n",
        "class OcrPredictor:\n",
        "    def __init__(self, model_path, config, device='cpu'):\n",
        "        self.tokenizer = Tokenizer(config['alphabet'])\n",
        "        self.device = torch.device(device)\n",
        "        # load model\n",
        "        self.model = CRNN(number_class_symbols=self.tokenizer.get_num_chars())\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.transforms = InferenceTransform(\n",
        "            height=config['image']['height'],\n",
        "            width=config['image']['width'],\n",
        "        )\n",
        "\n",
        "    def __call__(self, images):\n",
        "        if isinstance(images, (list, tuple)):\n",
        "            one_image = False\n",
        "        elif isinstance(images, np.ndarray):\n",
        "            images = [images]\n",
        "            one_image = True\n",
        "        else:\n",
        "            raise Exception(f\"Input must contain np.ndarray, \"\n",
        "                            f\"tuple or list, found {type(images)}.\")\n",
        "\n",
        "        images = self.transforms(images)\n",
        "        pred = predict(images, self.model, self.tokenizer, self.device)\n",
        "\n",
        "        if one_image:\n",
        "            return pred[0]\n",
        "        else:\n",
        "            return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a3cc7c",
      "metadata": {
        "id": "65a3cc7c"
      },
      "source": [
        "Инициализируем OCR predictor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ocr-model-last.ckpt ocr-model-last.ckpt"
      ],
      "metadata": {
        "id": "Jn9OQuI_hRrS"
      },
      "id": "Jn9OQuI_hRrS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec949ffd",
      "metadata": {
        "id": "ec949ffd"
      },
      "outputs": [],
      "source": [
        "predictor = OcrPredictor(\n",
        "    model_path='ocr-model-last.ckpt',\n",
        "    config=config_json,\n",
        "    device='cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b0255b",
      "metadata": {
        "id": "30b0255b"
      },
      "source": [
        "Посмотрим несколько предсказаний и создадим финальный json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.Inf = np.inf"
      ],
      "metadata": {
        "id": "7bOg_V8IjQgg"
      },
      "id": "7bOg_V8IjQgg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab792ab",
      "metadata": {
        "id": "5ab792ab",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pred_json = {}\n",
        "\n",
        "print_images = True\n",
        "for val_img in val_data_splitted[10:15]:\n",
        "    img = cv2.imread(f'/content/drive/MyDrive/train_recognition_small/images/{val_img[0]}')\n",
        "\n",
        "    pred = predictor(img)\n",
        "    pred_json[val_img[0]] = pred\n",
        "\n",
        "    if print_images:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "        print('Prediction: ', predictor(img))\n",
        "        print('True: ', val_img[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f790f2fe",
      "metadata": {
        "id": "f790f2fe"
      },
      "source": [
        "Сохраням submission json с предсказаниями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3264ac64",
      "metadata": {
        "id": "3264ac64"
      },
      "outputs": [],
      "source": [
        "with open('prediction_HTR.json', 'w') as f:\n",
        "    json.dump(pred_json, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}